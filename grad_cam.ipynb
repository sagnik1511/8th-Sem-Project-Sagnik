{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sr233/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BMBaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, network, num_classes):\n",
    "        super(BMBaseModel, self).__init__()\n",
    "        if network == \"resnet\":\n",
    "            self.featurizer = torch.hub.load('pytorch/vision:v0.10.0', \"resnet18\", pretrained=True)\n",
    "        elif network == \"googlenet\":\n",
    "            self.featurizer = torch.hub.load('pytorch/vision:v0.10.0', \"googlenet\", pretrained=True)\n",
    "        elif network == \"inception\":\n",
    "            self.featurizer = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "        elif network == \"googlenet\":\n",
    "            self.featurizer = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
    "        #self.featurizer = self._freeze_layers(self.featurizer)\n",
    "        self.mid_blocks = nn.Sequential(\n",
    "                nn.Linear(1000, 2048),\n",
    "                #nn.ReLU(),\n",
    "                nn.Linear(2048, 1024),\n",
    "                #nn.ReLU(),\n",
    "                nn.Linear(1024, 256),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _freeze_layers(self, network):\n",
    "        for param in network.parameters():\n",
    "            param.requires_grad = False\n",
    "        return network\n",
    "    \n",
    "    def forward(self, x):\n",
    "        featurizer_op = self.featurizer(x)\n",
    "        flattened_op = featurizer_op.view(featurizer_op.shape[0], -1)\n",
    "        return self.output_layer(self.mid_blocks(flattened_op))\n",
    "    \n",
    "base_model = BMBaseModel(\"resnet\", 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1best_chkp = torch.load(\"E:\\\\bone-marrow cell classification\\\\results\\\\exp1\\\\exp1_best.pt\")\n",
    "base_model.load_state_dict(exp1best_chkp[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no value was provided for `target_layer`, thus set to 'featurizer.layer4'.\n"
     ]
    }
   ],
   "source": [
    "from torchcam.methods import SmoothGradCAMpp\n",
    "cam_extractor1 = SmoothGradCAMpp(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grad_cam(source, model,cam_extractor, save_dir):\n",
    "  img = Image.open(source)\n",
    "  img = img.resize((224, 224),Image.ANTIALIAS)\n",
    "  img = transforms.ToTensor()(img).unsqueeze(0)\n",
    "  out = model(img.cuda())\n",
    "  activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
    "  result = overlay_mask(to_pil_image(img.squeeze(0).cpu()), to_pil_image(activation_map[0].cpu(), mode='F'), alpha=0.5)\n",
    "  #plt.imshow(result);plt.axis('off');plt.tight_layout()\n",
    "  #plt.savefig(os.path.join(save_dir,source.split(\"\\\\\")[-1]))\n",
    "  result.save(os.path.join(save_dir,source.split(\"\\\\\")[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1model = base_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradcam_test\\ABE_00002.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sr233\\AppData\\Local\\Temp\\ipykernel_12836\\4050851166.py:3: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((224, 224),Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradcam_test\\ABE_00003.jpg\n",
      "gradcam_test\\ABE_00004.jpg\n",
      "gradcam_test\\ART_06027.jpg\n",
      "gradcam_test\\ART_06028.jpg\n",
      "gradcam_test\\ART_06029.jpg\n",
      "gradcam_test\\BAS_00012.jpg\n",
      "gradcam_test\\BAS_00013.jpg\n",
      "gradcam_test\\BAS_00014.jpg\n",
      "gradcam_test\\BLA_09012.jpg\n",
      "gradcam_test\\BLA_09013.jpg\n",
      "gradcam_test\\BLA_09014.jpg\n",
      "gradcam_test\\EBO_08027.jpg\n",
      "gradcam_test\\EBO_08028.jpg\n",
      "gradcam_test\\EBO_08029.jpg\n",
      "gradcam_test\\EOS_03012.jpg\n",
      "gradcam_test\\EOS_03013.jpg\n",
      "gradcam_test\\EOS_03014.jpg\n",
      "gradcam_test\\FGC_00039.jpg\n",
      "gradcam_test\\FGC_00040.jpg\n",
      "gradcam_test\\FGC_00041.jpg\n",
      "gradcam_test\\HAC_00012.jpg\n",
      "gradcam_test\\HAC_00013.jpg\n",
      "gradcam_test\\HAC_00014.jpg\n",
      "gradcam_test\\KSC_00017.jpg\n",
      "gradcam_test\\KSC_00018.jpg\n",
      "gradcam_test\\KSC_00019.jpg\n",
      "gradcam_test\\LYI_00035.jpg\n",
      "gradcam_test\\LYI_00036.jpg\n",
      "gradcam_test\\LYI_00037.jpg\n",
      "gradcam_test\\LYT_08019.jpg\n",
      "gradcam_test\\LYT_08020.jpg\n",
      "gradcam_test\\LYT_08021.jpg\n",
      "gradcam_test\\MMZ_02015.jpg\n",
      "gradcam_test\\MMZ_02016.jpg\n",
      "gradcam_test\\MMZ_02017.jpg\n",
      "gradcam_test\\MON_02039.jpg\n",
      "gradcam_test\\MON_02040.jpg\n",
      "gradcam_test\\MON_02041.jpg\n",
      "gradcam_test\\MYB_05016.jpg\n",
      "gradcam_test\\MYB_05017.jpg\n",
      "gradcam_test\\MYB_05018.jpg\n",
      "gradcam_test\\NGB_03019.jpg\n",
      "gradcam_test\\NGB_03020.jpg\n",
      "gradcam_test\\NGB_03021.jpg\n",
      "gradcam_test\\NGS_07005.jpg\n",
      "gradcam_test\\NGS_07006.jpg\n",
      "gradcam_test\\NGS_07007.jpg\n",
      "gradcam_test\\NIF_01157.jpg\n",
      "gradcam_test\\NIF_01158.jpg\n",
      "gradcam_test\\NIF_01159.jpg\n",
      "gradcam_test\\OTH_00279.jpg\n",
      "gradcam_test\\OTH_00280.jpg\n",
      "gradcam_test\\OTH_00281.jpg\n",
      "gradcam_test\\PEB_02025.jpg\n",
      "gradcam_test\\PEB_02026.jpg\n",
      "gradcam_test\\PEB_02027.jpg\n",
      "gradcam_test\\PLM_05035.jpg\n",
      "gradcam_test\\PLM_05036.jpg\n",
      "gradcam_test\\PLM_05037.jpg\n",
      "gradcam_test\\PMO_06003.jpg\n",
      "gradcam_test\\PMO_06004.jpg\n",
      "gradcam_test\\PMO_06005.jpg\n"
     ]
    }
   ],
   "source": [
    "test_files = sorted(glob(\"gradcam_test/*\"))\n",
    "save_dir = \"exp_results/exp1\"\n",
    "for fp in test_files:\n",
    "    print(fp)\n",
    "    visualize_grad_cam(fp, exp1model, cam_extractor1, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "212a5a6f66f63bf41c0b7177ca785a3218d2cefdcfea3cc7f3408c78a8f86411"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
